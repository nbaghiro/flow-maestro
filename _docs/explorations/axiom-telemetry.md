# Axiom.co Integration Exploration

**Date**: November 7, 2025
**Status**: Research Complete - Ready for Future Implementation
**Decision**: Recommended for Phase 2 Integration (Hybrid Approach)

---

## Executive Summary

Axiom.co is a **managed observability platform** purpose-built for AI/LLM applications that offers significant advantages over self-hosted solutions. After completing Sprint 1 (building our own SpanService), we've evaluated Axiom as a potential managed backend for production deployments.

**Recommendation**: Integrate Axiom using a **hybrid approach** - keep our SpanService for local development/queries, export to Axiom for production observability, AI-native dashboards, and long-term analytics.

---

## What is Axiom?

Axiom is an **Event Data Platform** that provides unified log, trace, and metrics capabilities with:

- **Event-driven architecture**: Custom "EventDB" with 95% compression
- **Serverless querying**: On-demand compute, no infrastructure management
- **AI-native features**: Built specifically for LLM/agent workflow observability
- **OpenTelemetry standard**: Works with our existing instrumentation
- **Usage-based pricing**: Predictable costs, generous free tier

**Key Differentiator**: While traditional observability tools (Datadog, New Relic) are general-purpose, Axiom is **purpose-built for AI engineering** with native token tracking, cost monitoring, and multi-step agent tracing.

---

## Core Features

### 1. AI/LLM Observability (Perfect for FlowMaestro!)

**Native AI Workflow Tracing:**
- Multi-step agent chain visualization with trace waterfall
- Inspect inputs/outputs at every stage of agent loops
- Identify high-latency steps in complex workflows
- Track unexpected errors in agentic systems

**Automatic Cost & Token Tracking:**
- Track costs across providers (OpenAI, Anthropic, Google, Cohere)
- Per-capability cost breakdowns
- Per-model usage analytics
- Per-user cost attribution
- Automatic token counting from OpenTelemetry attributes

**Pre-Built AI Dashboard:**
- Automatically appears when sending AI telemetry
- At-a-glance cost tracking
- Model performance comparison
- Latency distribution analysis
- Error rate monitoring

**Enhanced OpenTelemetry Attributes:**
Axiom augments the OTel spec with AI-specific attributes:
- `gen_ai.capability.name` - Feature/workflow identification
- `gen_ai.step.name` - Individual step tracking
- `gen_ai.prompt.tokens` - Token usage
- `gen_ai.completion.tokens` - Response tokens
- `gen_ai.model` - Model identifier
- `gen_ai.provider` - Provider (OpenAI, Anthropic, etc.)

**TypeScript SDK for AI:**
- `@axiomhq/ai` - Purpose-built SDK for generative AI
- Built on OpenTelemetry standard
- Model wrappers for automatic trace capture
- Integration with Vercel AI SDK

### 2. Core Observability Features

**Distributed Tracing:**
- OpenTelemetry native support
- Span waterfall visualization
- Parent-child relationship tracking
- Cross-service trace correlation
- Zero sampling (keep 100% of traces)

**Log Aggregation:**
- Real-time log ingestion
- Structured log support (JSON)
- APL (Axiom Processing Language) for queries
- Virtual fields for query-time transformation
- Retention up to years (configurable)

**Metrics (Coming Soon):**
- Time-series metrics storage
- Integration with existing metrics systems
- Custom dashboards

**Querying:**
- APL (Axiom Processing Language) - piped operations
- Sub-second query performance
- Serverless compute (no cold starts)
- Automatic query optimization
- "Spotlight" feature - automated analysis

**Dashboards & Alerting:**
- Pre-built dashboards (AI, general observability)
- Custom dashboard builder
- Real-time monitors
- Slack/PagerDuty/webhook integrations
- Spend alerts

### 3. Platform Features

**Compression & Storage:**
- 95% compression ratio (~20x reduction)
- Compressed storage at $0.03/GB/month
- Long-term retention (year+) economically viable

**Performance:**
- Petabyte-scale ingestion (178B rows/second capacity)
- Sub-second query response
- Serverless architecture (no infrastructure)
- Global edge deployment

**Security & Compliance:**
- SAML SSO (enterprise add-on)
- Directory Sync (enterprise add-on)
- Role-Based Access Control (RBAC)
- Audit logs
- SOC 2 compliant

**Developer Experience:**
- 5-minute setup (documented)
- CLI tooling
- Infrastructure as Code support
- Extensive integration library
- OpenTelemetry SDK

---

## Pricing Analysis

### Free Tier (Personal Plan)

**Always Free:**
- 500 GB/month data loading
- 10 GB-hours/month query compute
- 25 GB storage
- 30-day maximum retention
- 2 datasets, 256 fields per dataset
- 1 user, 3 monitors

**Perfect for:**
- Development environments
- Small teams
- Early-stage products
- Proof of concept

### Paid Tier (Axiom Cloud)

**Base Structure:**
- $25/month minimum platform fee
- Usage-based billing (credits system)
- 1 credit = $1 (discounts with volume)

**Always Free Allowances (higher than Personal):**
- 1,000 GB/month data loading (2x free tier)
- 100 GB-hours/month query compute (10x free tier)
- 100 GB storage (4x free tier)

**Credit Pricing:**
- Data loading: $0.096-0.12/GB (volume discounts)
- Query compute: $0.12-0.2/GB-hour
- Storage: $0.030/GB/month (compressed)

**Volume Discounts (Pre-Purchase):**
- 25K-99K credits: $0.90/credit (10% off)
- 100K-249K credits: $0.85/credit (15% off)
- 250K-499K credits: $0.80/credit (20% off)
- 500K-999K credits: $0.75/credit (25% off)
- 1M+ credits: $0.70/credit (30% off)

### Enterprise Add-Ons

- SAML SSO: $100/month
- Directory Sync: $100/month
- RBAC: $50/month
- Audit Logs: $50/month

### Cost Examples for FlowMaestro

#### Scenario 1: Development (Light Usage)
**Volume:** 100 GB spans/month
- Ingestion: Covered by free tier (500 GB/month)
- Storage: ~5 GB compressed Ã— $0.03 = $0.15/month
- Query: Covered by free tier (10 GB-hours/month)
- **Total: $0/month** âœ…

#### Scenario 2: Growing Production (Moderate Usage)
**Volume:** 1 TB spans/month
- Ingestion: Covered by free allowance (1,000 GB/month)
- Storage: ~50 GB compressed Ã— $0.03 = $1.50/month
- Query: ~20 GB-hours (some covered, rest ~$2/month)
- **Total: $25 + $1.50 + $2 = $28.50/month**

#### Scenario 3: High Scale Production
**Volume:** 5 TB spans/month
- Ingestion: 5,000 GB Ã— $0.096 = $480/month
- Storage: ~250 GB compressed Ã— $0.03 = $7.50/month
- Query: ~100 GB-hours Ã— $0.12 = $12/month
- **Total: $25 + $480 + $7.50 + $12 = $524.50/month**

**Comparison to Alternatives:**
- AWS CloudWatch (5TB/day): ~$79,500/month
- Datadog (5TB/month): ~$5,000-10,000/month
- Self-hosted Grafana Loki: ~$200-500/month (infra) + ops time
- **Axiom: $525/month (90-95% cheaper)** ğŸ¯

---

## Axiom vs Self-Hosted Comparison

### Our Current Setup (Post Sprint 1)

**What We Built:**
- SpanService with batching and auto-flush
- PostgreSQL storage with 9 optimized indexes
- RequestContext for distributed tracing
- Structured logging with correlation IDs
- Tool validation with Zod

**Pros:**
- âœ… Full control over data
- âœ… No vendor lock-in
- âœ… Zero external costs (just database)
- âœ… Fast local queries (50-150ms)
- âœ… Custom features (RequestContext, tool validation)

**Cons:**
- âŒ Maintenance burden (migrations, backups, tuning)
- âŒ Scaling challenges (need to add infrastructure)
- âŒ No AI-native dashboards (need to build)
- âŒ Manual token tracking (via custom spans)
- âŒ No alerting (need to build)
- âŒ Storage costs grow linearly

### Axiom Managed

**Pros:**
- âœ… Zero operational overhead
- âœ… AI-native features (token tracking, cost dashboards)
- âœ… Pre-built dashboards
- âœ… Petabyte-scale automatically
- âœ… 95% compression (20x storage savings)
- âœ… Sub-second queries
- âœ… Built-in alerting
- âœ… OpenTelemetry standard

**Cons:**
- âŒ Vendor lock-in (mitigated by OTel standard)
- âŒ Network latency for queries
- âŒ Monthly costs (after free tier)
- âŒ 30-day retention on free tier (paid: configurable)

### Side-by-Side Comparison

| Feature | Self-Hosted (Ours) | Axiom Managed | Winner |
|---------|-------------------|---------------|--------|
| **Setup Time** | 6 hours | 5-10 minutes | Axiom |
| **Maintenance** | Ongoing (migrations, backups) | Zero | Axiom |
| **AI Features** | Custom (manual token tracking) | Native (automatic) | Axiom |
| **Dashboards** | Need to build | Pre-built | Axiom |
| **Scaling** | Manual | Automatic | Axiom |
| **Query Speed** | 50-150ms (local) | Sub-second (serverless) | Tie |
| **Cost (dev)** | $0 | $0 (free tier) | Tie |
| **Cost (prod 1TB)** | ~$50/mo + ops time | ~$28/month | Axiom |
| **Cost (prod 5TB)** | ~$200/mo + ops time | ~$525/month | Context-dependent |
| **Data Control** | Full | Vendor-managed | Self-hosted |
| **Compression** | 2-3x (JSONB) | 20x (95%) | Axiom |
| **Retention** | Custom (we control) | 30 days free, paid: years | Self-hosted |
| **Alerting** | Need to build | Built-in | Axiom |
| **Log Aggregation** | Need to add | Native | Axiom |
| **Custom Features** | Full flexibility | API/SDK limits | Self-hosted |

---

## Integration Strategies

### Option A: Hybrid Approach (RECOMMENDED)

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FlowMaestro   â”‚
â”‚    Backend      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ SpanSvc â”‚       â”‚ Axiom   â”‚
    â”‚  Local  â”‚       â”‚ Exporterâ”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚PostgreSQLâ”‚      â”‚ Axiom   â”‚
    â”‚  (Fast) â”‚       â”‚ (Cloud) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**
```typescript
// backend/src/shared/observability/axiom-exporter.ts
import { OTLPTraceExporter } from "@opentelemetry/exporter-trace-otlp-http";

export class AxiomExporter {
    private exporter: OTLPTraceExporter;

    constructor() {
        this.exporter = new OTLPTraceExporter({
            url: "https://api.axiom.co/v1/traces",
            headers: {
                "Authorization": `Bearer ${process.env.AXIOM_TOKEN}`,
                "X-Axiom-Dataset": process.env.AXIOM_DATASET || "flowmaestro-traces"
            }
        });
    }

    async export(spans: Span[]): Promise<void> {
        // Convert to OTel format and export
        const otlpSpans = spans.map(this.convertToOTLP);
        await this.exporter.export(otlpSpans);
    }

    private convertToOTLP(span: Span): OTLPSpan {
        // Convert our span format to OTel format
    }
}

// Modify SpanService.flush()
async flush(): Promise<void> {
    if (this.spanBatch.length === 0) return;

    const spans = [...this.spanBatch];
    this.spanBatch = [];

    // Dual-write: PostgreSQL + Axiom (non-blocking)
    await Promise.allSettled([
        this.flushToPostgres(spans),
        this.flushToAxiom(spans)  // Best-effort, don't fail if Axiom down
    ]);
}
```

**Benefits:**
- âœ… Keep fast local queries (development)
- âœ… Get AI-native dashboards (production)
- âœ… Zero migration effort (additive change)
- âœ… Fallback if Axiom is down
- âœ… Easy to toggle on/off
- âœ… Best of both worlds

**Drawbacks:**
- Slight complexity (two backends)
- Need to manage Axiom credentials
- Small network overhead

**When to Use:**
- Development: Query PostgreSQL (fast, local)
- Production: View Axiom dashboards (managed, scalable)
- Debugging: Use both (local detail + long-term trends)

### Option B: Axiom-Only (Full Migration)

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FlowMaestro   â”‚
â”‚    Backend      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Axiom   â”‚
    â”‚   SDK   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Axiom   â”‚
    â”‚ (Cloud) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**
```typescript
// Replace SpanService with Axiom SDK
import { Axiom } from "@axiomhq/js";

const axiom = new Axiom({
    token: process.env.AXIOM_TOKEN,
    dataset: "flowmaestro-traces"
});

// Send spans directly
await axiom.ingest("traces", spans);

// Query spans
const results = await axiom.query(`
    ['traces']
    | where userId == 'user-123'
    | where span_type == 'agent_run'
    | project timestamp, name, duration_ms, attributes
`);
```

**Benefits:**
- âœ… Simplest architecture
- âœ… Lowest maintenance
- âœ… Native AI features
- âœ… No local database needed

**Drawbacks:**
- âŒ Lose local query capability
- âŒ Vendor lock-in (mitigated by OTel)
- âŒ Network latency for all queries
- âŒ Migration effort (remove SpanService)

**When to Use:**
- Pure cloud deployment
- No local development needs
- Want minimal infrastructure
- Trust Axiom uptime

### Option C: PostgreSQL-Only (Current State)

**Keep our current setup, no Axiom integration**

**Benefits:**
- âœ… Full control
- âœ… No vendor costs
- âœ… No vendor dependencies

**Drawbacks:**
- âŒ No AI-native dashboards
- âŒ Manual token tracking
- âŒ Ongoing maintenance
- âŒ Scaling challenges

**When to Use:**
- Strict data sovereignty requirements
- Very small scale (< 100GB/month)
- Strong DevOps team available

---

## Recommended Integration Plan

### Phase 1: Add Axiom Exporter (1-2 hours)

**Goal**: Export spans to Axiom in parallel with PostgreSQL storage

**Tasks:**
1. Install Axiom packages
   ```bash
   npm install @axiomhq/js @opentelemetry/exporter-trace-otlp-http
   ```

2. Create Axiom account and get API token
   - Sign up: https://app.axiom.co
   - Create dataset: `flowmaestro-traces`
   - Generate API token

3. Add environment variables
   ```bash
   AXIOM_TOKEN=your_token_here
   AXIOM_DATASET=flowmaestro-traces
   AXIOM_ENABLED=true  # Toggle for dev/prod
   ```

4. Create AxiomExporter class
   - Location: `backend/src/shared/observability/axiom-exporter.ts`
   - Convert spans to OTel format
   - Export via OTLP HTTP

5. Update SpanService.flush()
   - Add dual-write to PostgreSQL and Axiom
   - Make Axiom export non-blocking (best-effort)
   - Add error handling (log but don't fail)

6. Test locally
   - Start backend
   - Trigger agent execution
   - Verify spans appear in Axiom dashboard

**Success Criteria:**
- âœ… Spans visible in Axiom dashboard
- âœ… Pre-built AI dashboard appears
- âœ… Token usage tracked automatically
- âœ… No impact on local query performance

**Estimated Time**: 1-2 hours

### Phase 2: Configure AI Dashboard (30 minutes)

**Goal**: Set up monitoring and alerting in Axiom

**Tasks:**
1. Configure pre-built AI dashboard
   - Token usage by model
   - Cost by capability
   - Latency distribution
   - Error rates

2. Set up monitors
   - High token usage alert (> 1M tokens/day)
   - High cost alert (> $100/day)
   - High error rate alert (> 5%)
   - Slow execution alert (p95 > 10s)

3. Configure integrations
   - Slack for critical alerts
   - Email for daily summaries

**Success Criteria:**
- âœ… Dashboard shows real-time metrics
- âœ… Alerts trigger correctly
- âœ… Team has visibility into costs

**Estimated Time**: 30 minutes

### Phase 3: Evaluate Value (1-2 weeks)

**Goal**: Assess whether Axiom provides sufficient value

**Metrics to Track:**
1. **Query Performance**
   - Local (PostgreSQL): measure query times
   - Axiom: measure query times
   - Compare usability

2. **Cost Analysis**
   - Axiom usage (GB ingested, storage, compute)
   - Projected monthly cost
   - Compare to self-hosted costs (infra + ops time)

3. **Feature Utilization**
   - AI dashboard usage
   - Alert effectiveness
   - Query frequency
   - Dashboard views

4. **Developer Experience**
   - Time saved on debugging
   - Insights gained from dashboards
   - Ease of querying

**Decision Points:**
- If value > cost: Continue with Axiom, consider upgrading tier
- If value < cost: Disable Axiom, stick with PostgreSQL
- If unclear: Extend evaluation period

**Estimated Time**: 1-2 weeks of usage

### Phase 4: Optimize or Migrate (Optional)

**Option A: Optimize Hybrid**
- Fine-tune what data goes to Axiom
- Keep only production in Axiom
- Use PostgreSQL for dev/test

**Option B: Full Migration to Axiom**
- Remove PostgreSQL span storage
- Use Axiom as primary backend
- Keep RequestContext and tool validation

**Option C: Remove Axiom**
- Disable exporter
- Enhance PostgreSQL dashboards
- Build custom alerting

---

## Technical Integration Details

### OpenTelemetry Compatibility

Axiom is fully compatible with OpenTelemetry, meaning:

1. **Our SpanService is compatible**
   - We use OTel-style attributes
   - We have trace/span IDs
   - We track parent-child relationships

2. **Conversion is straightforward**
   ```typescript
   // Our span format
   {
       traceId, spanId, parentSpanId,
       name, spanType, entityId,
       startedAt, endedAt, durationMs,
       input, output, error,
       attributes: { userId, modelId, tokens, ... }
   }

   // OTel format (what Axiom expects)
   {
       traceId, spanId, parentSpanId,
       name, kind,
       startTime, endTime,
       attributes: {
           "gen_ai.capability.name": entityId,
           "gen_ai.model": modelId,
           "gen_ai.prompt.tokens": tokens,
           "userId": userId,
           ...
       }
   }
   ```

3. **We can add AI-specific attributes**
   ```typescript
   // Enhance our spans with Axiom's AI attributes
   attributes: {
       "gen_ai.capability.name": "customer-support-agent",
       "gen_ai.step.name": "llm-generation",
       "gen_ai.model": "gpt-4o",
       "gen_ai.provider": "openai",
       "gen_ai.prompt.tokens": 100,
       "gen_ai.completion.tokens": 50,
       "gen_ai.total.tokens": 150,
       // ... our existing attributes
   }
   ```

### Axiom TypeScript SDK

```typescript
// @axiomhq/js - Core SDK
import { Axiom } from "@axiomhq/js";

const axiom = new Axiom({ token: process.env.AXIOM_TOKEN });

// Ingest events
await axiom.ingest("dataset", [{ ... }]);

// Query with APL
const result = await axiom.query(`
    ['dataset']
    | where timestamp > ago(1h)
    | summarize count() by bin(timestamp, 5m)
`);

// @axiomhq/ai - AI-specific SDK (experimental)
import { trace } from "@axiomhq/ai";

const traced = trace(myLLMFunction, {
    capability: "customer-support",
    model: "gpt-4o"
});
```

### APL Query Language

Axiom uses APL (Axiom Processing Language), similar to KQL (Kusto Query Language):

```sql
-- Get all agent runs for a user in last 24h
['flowmaestro-traces']
| where timestamp > ago(24h)
| where span_type == "agent_run"
| where attributes.userId == "user-123"
| project timestamp, name, duration_ms, attributes.totalTokens
| order by timestamp desc

-- Token usage by model (last 7 days)
['flowmaestro-traces']
| where timestamp > ago(7d)
| where span_type == "model_generation"
| summarize
    total_tokens = sum(tolong(attributes["gen_ai.total.tokens"])),
    calls = count()
  by model = tostring(attributes["gen_ai.model"])
| extend cost = total_tokens * 0.00003  // $0.03 per 1K tokens
| order by cost desc

-- P95 latency by capability
['flowmaestro-traces']
| where span_type == "agent_run"
| summarize
    p95_duration = percentile(duration_ms, 95),
    count = count()
  by capability = tostring(attributes["gen_ai.capability.name"])
| order by p95_duration desc
```

---

## Customer Case Studies

### Temporal.io + Axiom (Relevant!)

**Source**: Blog post "Using pino & axiom for logging in TypeScript Worker for Temporal.io"

**Key Takeaways:**
- Temporal workflows generate significant log volume
- Axiom handles Temporal logs effectively
- Integration via Pino transport
- Cost-effective for high-volume workflows

**Our Relevance:**
- We use Temporal for workflows and agents
- We use Pino for logging
- Exact same use case!

### Cal.com (High-Volume SaaS)

**Quote**: "Axiom allows me to affordably see all my logs for a year"

**Key Takeaway:**
- Year-long retention is economically viable
- Previously cost-prohibitive with other tools

**Our Relevance:**
- Need long-term trace data for debugging
- Want to analyze historical patterns
- Cost is a concern at scale

### Vercel, Netlify (Edge Computing)

**Key Takeaway:**
- Axiom handles massive edge event volumes
- Serverless-friendly architecture
- Fast ingestion from distributed sources

**Our Relevance:**
- Distributed Temporal workers
- High event volume (agent iterations)
- Need real-time visibility

---

## Migration Considerations

### Data Retention Strategy

**Current (PostgreSQL):**
- Keep all spans indefinitely (until manual cleanup)
- Storage grows linearly
- Need to implement rotation

**With Axiom:**
- Free tier: 30-day retention
- Paid tier: Configurable (months to years)
- Automatic data lifecycle management

**Hybrid Strategy:**
- Short-term (7 days): PostgreSQL (fast queries)
- Long-term (30+ days): Axiom (analytics, compliance)
- Automatic archival after 7 days

### Query Migration

**Current (SQL):**
```sql
SELECT * FROM execution_spans
WHERE span_type = 'agent_run'
AND attributes->>'userId' = 'user-123'
ORDER BY started_at DESC;
```

**Axiom (APL):**
```sql
['flowmaestro-traces']
| where span_type == "agent_run"
| where attributes.userId == "user-123"
| order by timestamp desc
```

**Learning Curve**:
- APL is similar to SQL with piped operations
- Most queries translate directly
- Some PostgreSQL-specific functions need equivalents

### Cost Optimization

**Tips to Minimize Axiom Costs:**

1. **Filter at source**
   - Only export production spans
   - Skip debug/trace level spans
   - Sample high-frequency events

2. **Optimize attributes**
   - Use consistent attribute names
   - Avoid high-cardinality attributes
   - Keep attribute values concise

3. **Smart retention**
   - Short retention for verbose logs
   - Long retention for critical traces
   - Archive to S3 for compliance

4. **Query efficiently**
   - Use time filters (avoid full scans)
   - Leverage sampling for trends
   - Pre-aggregate when possible

5. **Monitor usage**
   - Set up cost alerts
   - Review usage dashboards weekly
   - Adjust ingestion as needed

---

## Risks & Mitigations

### Risk 1: Vendor Lock-In

**Risk**: Dependency on Axiom platform

**Mitigation**:
- Use OpenTelemetry standard (portable)
- Keep hybrid approach (can switch off Axiom)
- Export critical data to S3 for backup
- Maintain our SpanService as fallback

### Risk 2: Cost Overruns

**Risk**: Unexpected high costs at scale

**Mitigation**:
- Start with free tier (500GB/month)
- Set up spend alerts ($100, $500, $1000)
- Monitor usage dashboard daily
- Implement sampling if needed
- Can disable export anytime

### Risk 3: Network Dependency

**Risk**: Axiom unavailable â†’ observability gap

**Mitigation**:
- Dual-write to PostgreSQL (fallback)
- Async export (doesn't block operations)
- Local buffering if network down
- Graceful degradation

### Risk 4: Data Privacy

**Risk**: Sensitive data exported to third party

**Mitigation**:
- Review data before enabling
- Scrub PII from span attributes
- Use field-level encryption if needed
- GDPR/CCPA compliance (Axiom is compliant)

### Risk 5: Learning Curve

**Risk**: Team unfamiliar with APL queries

**Mitigation**:
- APL is similar to SQL (easy transition)
- Extensive documentation available
- Pre-built dashboards (no queries needed)
- Can use both PostgreSQL and Axiom during transition

---

## Decision Framework

### Choose Axiom If:

âœ… You want **AI-native observability** (token tracking, cost dashboards)
âœ… You need **zero operational overhead** (no database maintenance)
âœ… You're scaling **beyond 1TB/month** (compression saves money)
âœ… You want **long-term retention** (year+) economically
âœ… You value **pre-built dashboards** over custom building
âœ… You're comfortable with **managed services** (less control)
âœ… Your team prefers **fast iteration** over infrastructure work

### Keep Self-Hosted If:

âœ… You have **strict data sovereignty** requirements
âœ… You need **full control** over retention/queries
âœ… You have **< 100GB/month** (self-hosted is cheaper)
âœ… You have **strong DevOps team** (maintenance isn't a burden)
âœ… You need **custom features** not available in Axiom
âœ… You want **zero vendor dependencies**
âœ… You prefer **infrastructure work** over monthly costs

### Use Hybrid If:

âœ… You want **best of both worlds**
âœ… You need **fast local queries** (development)
âœ… You want **managed dashboards** (production)
âœ… You're **evaluating** Axiom (no commitment)
âœ… You want **gradual migration** (low risk)
âœ… You need **fallback options** (high reliability)

---

## Conclusion

### Our Recommendation

**âœ… YES - Integrate Axiom with Hybrid Approach**

**Why:**
1. **Keep our work** - SpanService, RequestContext, tool validation are valuable
2. **Add Axiom backend** - Get AI-native features for production
3. **Low risk** - Additive change, easy to disable
4. **Free to start** - 500GB/month covers development
5. **Production-proven** - Used by Vercel, Netlify, Asana
6. **Perfect timing** - Just completed Sprint 1, perfect to extend

**Implementation:**
- Phase 1 (1-2 hours): Add Axiom exporter
- Phase 2 (30 min): Configure dashboards
- Phase 3 (1-2 weeks): Evaluate value
- Phase 4 (optional): Optimize or migrate

**Our Work Wasn't Wasted:**
- âœ… We understand observability deeply
- âœ… We have local querying for development
- âœ… We can switch backends anytime (OTel)
- âœ… We have RequestContext and tool validation (keep!)
- âœ… We have a solid foundation to build on

### Next Steps

1. **Complete Mastra-inspired changes** (Sprint 2-4)
   - ConversationManager
   - WorkingMemoryService
   - Multi-agent orchestration
   - Storage abstraction
   - Node-level suspend/resume

2. **Revisit Axiom integration** (After Sprint 4)
   - Implement Phase 1 (Axiom exporter)
   - Evaluate in production
   - Make go/no-go decision

3. **Document learnings**
   - Update this document with actual results
   - Share cost analysis
   - Provide integration guide

---

## References

### Documentation
- Axiom Docs: https://axiom.co/docs
- OpenTelemetry Node.js: https://axiom.co/docs/guides/opentelemetry-nodejs
- AI SDK Integration: https://ai-sdk.dev/providers/observability/axiom
- Temporal + Axiom: https://pmbanugo.me/blog/how-to-collect-temporalio-logs-using-axiom-and-pino

### Pricing
- Axiom Pricing: https://axiom.co/pricing
- Free Tier Details: 500GB/month, 30-day retention
- Cost Calculator: Available in Axiom dashboard

### SDKs
- @axiomhq/js: https://github.com/axiomhq/axiom-js
- @axiomhq/ai: https://github.com/axiomhq/ai (AI-specific SDK)
- OpenTelemetry: https://opentelemetry.io/docs/languages/js/

### Comparisons
- Axiom vs CloudWatch: 70% cost savings
- Axiom vs Datadog: 90% cost savings
- Axiom vs Self-Hosted: Operational overhead vs monthly cost

---

**Document Status**: Complete - Ready for implementation after Sprint 2-4
**Last Updated**: November 7, 2025
**Author**: Development Team
**Next Review**: After Sprint 4 completion
